[data]
robot_path = data/robot/toroboarmsim_2o2g_120_softmax10.npy
training_path = output/toroboarmsim_2o2g_120
sequences = 120
max_timesteps = 80
robot_dims = 17
softmax_quant = 10
robot_softmax_min = -30
robot_softmax_max = 120
robot_softmax_sigma = 220

[network]
learning_rate = 0.001
gradient_clip = 0
gradient_clip_input = 0
modalities = robot
optimizer = adam
robot_celltype = MTRNN
robot_activation_func = tanh
robot_meta_prior = 0.0008, 0.0004, 0.0002
robot_layers_neurons = 30, 20, 10
robot_layers_z_units = 3, 2, 1
robot_layers_param = 2, 4, 8
connect_bottomup_d = False
ugaussian_t_range = 0, 1
ugaussian_weight = 0.001

[training]
max_epochs = 100000
#fig_xy_dims = 9, 8
#fig_x_lim = -20.0, 20.0
#fig_y_lim = 40.0, 70.0

[testing]
#fig_xy_dims = 9, 8
#fig_x_lim = -20.0, 20.0
#fig_y_lim = 40.0, 70.0

[planning]
max_epochs = 1000
init_modalities = robot
goal_modalities = robot
goal_modalities_mask = 8, 16
#fig_xy_dims = 9, 8
#fig_x_lim = -20.0, 20.0
#fig_y_lim = 40.0, 70.0
